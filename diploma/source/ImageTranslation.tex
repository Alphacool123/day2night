\documentclass[11pt,a4paper]{extarticle}
\usepackage{cmap}
\usepackage[utf8x]{inputenc}
\usepackage[T2A,T1]{fontenc}
\usepackage[hidelinks]{hyperref} 
\usepackage[russian,english]{babel}
\usepackage{listings,lstautogobble}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{xcolor,colortbl}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{enumerate}
\usepackage{perpage}
\usepackage{subcaption}
\usepackage{fullpage}
\usepackage[nottoc,numbib]{tocbibind}
\usepackage[russian,english]{babel}

\definecolor{Gray}{gray}{0.95}
\definecolor{Red}{rgb}{0.80,0.5,0.5}
\definecolor{Green}{rgb}{0.6,0.8,0.6}

\definecolor{Gray}{gray}{0.95}
\definecolor{Black}{gray}{0.1}
\definecolor{Red}{rgb}{0.80,0.5,0.5}
\definecolor{Green}{rgb}{0.6,0.8,0.6}

\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newlength{\twosubht}
\newsavebox{\twosubbox}
\setlength\headheight{26pt}

\lstdefinestyle{codestyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{Green},
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    autogobble=true,
    inputencoding=utf8x,
    extendedchars=\true
}

\lstset{style=codestyle}

\newenvironment{compactlist}{
\begin{list}{{$\bullet$}}{
\setlength\partopsep{0pt}
\setlength\parskip{0pt}
\setlength\parsep{0pt}
\setlength\topsep{0pt}
\setlength\itemsep{0pt}
}}{
\end{list}
}

\MakePerPage{footnote}


\begin{document}
\selectlanguage{russian}
\begin{titlepage}
	\begin{centering}
		\includegraphics{img/msu}\\
		\large{
			\textbf{Московский государственный университет имени М.В. Ломоносова}\\
			Факультет вычислительной математики и кибернетики\\
			Кафедра интеллектуальных информационных технологий\\
			Лаборатория компьютерной графики и мультимедиа\\[4cm]
		}
		\Large{
			Гончаренко Дмитрий Александрович\\[0.9cm]
		}
		\Large{
			\textbf{Алгоритм изменения времени суток на изображении}\\
			% \textbf{Research of Changing The Time of Day on Images}\\
		}
		\rule[0.3cm]{14cm}{0.02cm}\\[1cm]
		\large{
			ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА\\[4cm]
		}
	\end{centering}
	\begin{flushright}
		\large{
			\textbf{Научный руководитель:}\\ К.С. Зипа\\
		}
	\end{flushright}
	\begin{center}
		\vfill
		\large{
			Москва, 2019
		}
	\end{center}
\end{titlepage}

\begin{abstract}
	Алгоритм изменения времени суток на изображении относится к классу задач машинного обучения по \textit{переносу
	изображений}\footnote{
		\textbf{Перенос изображений} (англ. \textit{image translation}, или \textit{image transfering})
		-- подвид технологии переноса обучения, позволяющий сохранять и объединять локальные признаки изображений.
	}.
	Данная сфера значительное продвинулась благодаря современным вычислительным возможностям, в частности переносе обучения на графические процессоры, GPU.
	За последние несколько лет появилось немало исследовательских работ на тему переноса изображений, стилей и колоризации.
	В данной работе рассматриваются современные подходы к переносу изображений на примере изменения времени суток на изображении.
	Проводится описание нейросетевых моделей и сравнительный анализ серии экспериментов обучения.
\end{abstract}

\selectlanguage{english}
\begin{abstract}
	The algorithm of changing the time of the day on images is a subclass of Machine Learning problems of image translation.
	This area has advanced significantly due to the modern computing capabilities, in particular the training transfer on GPUs.
	Over the past few years, many research papers have appeared on the subjects of images translation, styles transfering and colorization.
	This research reveals modern approaches of image translation on the example of changing the time of day on the image.
	A description of the neural network models and a comparative quality analysis of a series of training experiments are carried out.
\end{abstract}
\selectlanguage{russian}

\newpage
\tableofcontents
\newpage

\section{Введение}
	Математические описания моделей машинного обучения появились еще в середине 20-го века.
	А первые попытки их практической реализации начались в конце 50х годов.
	В наше время задачи машинного обучения все также не теряют своей актуальности.
	Рост числа работ, открытие исследовательских центров внутри компаний и при университетах показывает высокий интерес к данной сфере не только в науке.
	Появление удобных и современных инструментов для построения самых разнообразных моделей обучения,
	возможности мгновенно обмениваться информацией -- оказало немалое влияние на развитие \textit{науки о данных}\footnote{
		\textbf{Наука о данных} (англ. \textit{data science}) -- соовокупность процессов и методов направленных на извлечение информации из исследуемых данных.
	}.  
	
	Стоит отметить, что не последнюю роль здесь сыграли многократно выросшие вычислительные возможности. 
	Это позволило обучать \textit{нейронные сети}\footnote{
		\textbf{Нейронная сеть} --  математическая модель, а также её программное или аппаратное воплощение, 
		построенная по принципу организации и функционирования биологических нейронных сетей -- сетей нервных клеток живого организма.
		Является мощным современным инструментом машинного обучения.
		Главная особенность -- способность обучаться на предоставленных данных, называемых тренировочными.
		Помимо исследовательских направлений нейронные сети также активно используются в комерции, например обработка спама на электронной почте или система рекомендаций в интернет-магазинах.
	} на персональных компьютерах за доли секунды, для чего ранее могли требоваться дни, а то и недели на специализированных вычислительных устройствах.

	\textit{Перенос обучения} является одной из центральных исследовательских задач современного машинного обучения.
	Данная область направленна на получение некоторой информации об объекте, сохранение и последующее применение этих знаний к другому объекту, связанному с первым.   
	\textit{Перенос изображений}, в свою очередь, является подклассом переноса обучения применяемым на изображениях. 
	В настоящее время перенос изображений используется самыми разнообразными способами.
	С помощью него можно добиться объединения стилей двух изображений \cite{style_transfer},
	колоризации\footnote{
		\textbf{Колоризация} (англ. \textit{colorization}) -- преобразование монохромных изображений в цветные.
	} черно-белых фотографий \cite{color_transfer}, объединение локальных признаков объектов и животных \cite{CycleGAN},
	увеличение разрешения изображений \cite{super_resolution}.

	В данной исследовательской работе рассматриваются и систематизируются современные подходы переноса изображений, на примере изменения времени суток на изображениях.
	А также проводится обучение моделей на различных наборах данных и сравнительный анализ полученных результатов с использованием предложенной метрики.
	
	В качестве инструмента был выбран фреймворк PyTorch\footnote{
		\textbf{PyTorch} -- библиотека машинного обучения, основанная на Torch. Разработана исследовательской группой в Facebook.
	}, так как он разработан в виде библиотеки для языка Python - основного языка современного машинного обучения \cite{ml_lang},
	и зарекомендовал себя мощным и гибким инструментом для исследования и обучения нейронных сетей.

\newpage
\section{Постановка задачи}
	\subsection{Цель работы}
		В науке о данных одну из ключевых ролей играет непосредственный выбор данных, на которых будет обучаться сеть, 
		и которые будут использоваться для валидации качества модели. Перенос изображений не является исключением.
		Цель работы -- получить модель, которая будет уметь с высокой точностью переносить изображения между \textit{доменами}\footnote{
			\textbf{Домен} -- область, множество, содержащее в себе объекты одного типа. 
		} и способную решить проблему изменения времени суток на изображениях с приемлемой точностью.
	
	\subsection{Решаемые задачи}
		Проблему изменения времени суток на изображении можно разбить на следующие этапы:

		\begin{compactlist}
			\item Исследование существующих методов переноса изображений и анализ решений родственных задач
			\item Поиск применимых к проблеме тренировочных данных -- изображений с различными временами суток, и их применение
			\item На основе проведенного исследования и обзора литературы, выбор модели, подходящей для решения поставленной задачи
			наилучшим образом
			\item Множественное обучение выбранной модели на различных конфигурациях с помощью библиотеки PyTorch
			\item Разработка и применение метрики качества обучения для выявления наилучших параметров сети
			\item Проведение серии экспериментов переноса изображений для получения оценки качества и скорости работы модели 
		\end{compactlist}

	\subsection{Формальная постановка задачи}
		Формально алгоритм изменения времени суток на изображении можно сформулировать следующим образом:

		\subsubsection*{Вход}
			На вход алгоритму поступают два изображения из различных доменов \(x_{1} \in X_{1}\)  и \(x_{2}\ \in X_{2}\), где
			\begin{itemize}
				\item \(X_{1}\) -- домен с набором изображений первого типа
				\item \(X_{2}\) -- домен с набором изображений второго типа
			\end{itemize}
			Не ограничивая общности, пусть \(X_{1}\) соодержит изображения дня, а \(X_{2}\) соответвует ночи.
		\subsubsection*{Выход}
			Необходимо построить \textit{кросдоменные}\footnote{
				\textbf{Кросдоменный перенос} (англ. \textit{cross-domain transfer}) -- перенос объектов между доменами 
			} отображения \(f_{12}\!: X_{1} \longrightarrow X_{2}\) и \(f_{21}\!: X_{2} \longrightarrow X_{1}\).
			
			\noindent
			Реализовать функцию, принимающую на вход изображения из разных доменов
			\(x_{1}, x_{2}\) и возвращающую перенесенные изображения \(x_{2}', x_{1}'\) соответсвенно: 

			\begin{equation}
					x_{2}', x_{1}'  = CrossDomainTranslator(x_{1}, x_{2}),\ \text{где}\ x_{1}' \in X_{1},\ x_{2}' \in X_{2}
			\end{equation}
	
	\newpage
	\section{Обзор существующих методов}
		
		Одними из наиболее популярных алгоритмов, на которых базируются решения многих задач переноса изображений, на сегодняшний день являются
		генеративно состязательные нейронные сети и вариационные автоэнкодеры.
		Для того чтобы в дальнейшем опрерировать этими понятиями, введем их формальные определения.

		\textbf{Генеративно состязательная нейронная сеть} (GAN) -- комбинация двух нейронных сетей $G$ (генератор) и $D$ (дискриминатор).
		Генератор подбирает \textit{латентные}\footnote{
			\textbf{Латентный} здесь и далее, то же что и скрытый
		} параметры для генерации нового объекта.
		Дискриминатор пытается отличить оригинал от объекта, созданного генератором.
		
		\begin{figure}[ht]
			\centering
			\includegraphics[width=0.8\textwidth]{img/gan}
			\caption{Схема работы генеративно состязательной сети (GAN)}
			\label{ganmodel}
		\end{figure}
		\noindent
		Формально генератор можно определить как отображение некоторого пространства скрытых параметров $\mathcal{Z}$,
		на котором задано априорное распределение \(p_z(z)\), в прострасво данных $\mathcal{X}$.
		Дескриминатор же будет производить отображение $\mathcal{X}$ в отрезок $[0,1]$ -- вероятность того, что пример настоящий.
		На рис. \ref{ganmodel} представлена общая схема работы генеративной сети.
		\begin{equation}
			\begin{aligned}
				& G\!:{\mathcal{Z}}\rightarrow {\mathcal{X}} \\
				& D\!:{\mathcal{X}}\rightarrow [0,1]
			\end{aligned}
		\end{equation}
		Основной целью генеративно состязательной сети является получение генератором распределения данных $p_{gen}$,
		не отличимого дискриминатором от исходного распределения $p_{data}$.
		То есть, по сути, заключается в решении задачи оптимизации \cite{Deep_Learning}:
		\begin{equation}
			\min_{G} \max_{D} V(D,G), \text{ где }
		\end{equation}
		\begin{equation*}
			V(D,G) = \mathbb{E}_{x∼p_{data}(x)}[\log{D(x)}] + \mathbb{E}_{x∼p_{z}(z)}[\log (1 - D(G(z)))]
		\end{equation*}
		\indent
		\textbf{Автоэнкодер} (AE) -- комбинация двух нейронных сетей $E$ (энкодера или кодировщика) и $D$ (декодера).
		Энкодер получает и преобразует данные в сжатый код скрытого пространства.
		Декодер же старается из этого кода восстановить объект наиболее близкий к исходному.
		Математически можно представить автоэнкодер как отображения пространства входных данных $\mathcal{X}$ в латентное пространство $\mathcal{Z}$ и обратно:
		\begin{equation}
			\begin{aligned}
				& E\!:{\mathcal{X}}\rightarrow {\mathcal{Z}} \\
				& D\!:{\mathcal{Z}}\rightarrow {\mathcal{X}} \\
				x& \xrightarrow[]{E} z \xrightarrow[]{D} x', \text{ где }
			\end{aligned}
		\end{equation}
		\begin{equation*}
			\begin{array}{ll}
				x\;\in \mathcal{X}&-\;\text{исходное изображение}\\
				z\;\in \mathcal{Z}&-\;\text{скрытый код}\\
				x' \in \mathcal{X}&-\;\text{восстановленное изображение}\\
			\end{array} 
		\end{equation*}

		\begin{figure}[ht]
			\centering
			\includegraphics[width=0.8\textwidth]{img/vae}
			\caption{Общая схема работы автоэнкодеров (AE)}
			\label{aemodel}
		\end{figure}
		\noindent
		Задача автокодировщика состоит в минимизации разницы между исходным изображением $x$ и восстановленным $x'$.
		Для этого введем функцию потерь $\mathcal{L}$, характеризующую потери при неправильном принятии решений:
		\begin{equation}
			\mathcal{L}(x,x') = \|x - x'\|^{2}
		\end{equation}
		Основная проблема автоэнкодеров заключается в том, что скрытое пространство, может не быть непрерывным.
		Из-за чего не получается произвести интерполяцию, и как следствие, их область применения ограничивается.
		Эту проблему способны решить некоторые дополнительные предположения описаные ниже.
		
		\textbf{Вариационный автоэнкодер} (VAE) отличается от автоэнкодера непрерывностью латентного пространства
		и предположениями накладываемыми на распределенность данных в скрытом пространстве.
		Кодировщику, в этом случае, можно сопоставить апостериорное распределение\footnote{
			\textbf{Апостерироное распределение} -- распределенеие случайного события при условии того, что известны апостериорные данные, т.е. полученные после опыта.
		}
		 $q_{\theta}(z|x)$, где $x$ -- пример из набора данных.

		% Из-за уменьшения размерности вариационный автоэнкодер учится игнорировать шум, что позволяет получать более четкие изображения в связке с GAN.\\

		% расстояние Кульбака-Лейблера - несимметричная мера «похожести» двух распределений
		\noindent
		\\Пусть \(X_{1}\) и \(X_{2}\) два домена изображений. Пусть даны изображения \(x_{1},x_{2}: x_{1} \in X_{1}, x_{2} \in X_{2}\)%} \tag{\(*\)}\label{assume} &
		\subsection{Методы использующие обучение с учителем}
			\textbf{Обучение с учителем} (англ. \textit{supervised learning}) -- способ машинного обучения, в ходе которого входные данные соотносятся с выходными до начала обучения.
			Обучение происходит на заготовленных парах объектов (\(x_{1},x_{2}\)), которые находятся в доменах в некотором совместном распределении \(P_{X_{1},X_{2}}(x_{1},x_{2})\)\footnote{
				\textbf{Совместное распределение} -- это распределение совместных исходов образованных из нескольких случайных величин.
			}.
			Задача метода -- построить функцию внутренней зависимости между примерами, которая затем будет отображать входные изображения желаемым образом.

			Успешными примерами применения этого способа для решения задач переноса изображения можно считать эти работы \cite{BicycleGAN, pix2pix}.
		
		% \subsubsection{BicycleGAN}

		\subsection{Методы использующие обучение без учителя}
			\textbf{Обучение без учителя} (англ. \textit{unsupervised learning}) -- совокупность задач машинного обучения, решаемых на неразмеченных данных.
			В отличие от обучения с учителем, где тренировочные данные находятся в совместном распределении \(P_{X_{1},X_{2}}(x_{1},x_{2})\), в методах без вмешательства учителя требуется
			найти априорное распределение, выбирая данные (\(x_{1},x_{2}\)) из доменов с частным распределением \(P_{X_{1}}(x_{1})\) и  \(P_{X_{2}}(x_{2})\)\footnote{
				\textbf{Частное распределение} -- это распределение вероятности компонент некоторого множества, без зависимости между компонентами.
			}.

			К наиболее интересным работам, использующим этот метод, можно отнести \cite{UNIT,MUNIT,CycleGAN}.

			
% \section{Исследование и построение решения задачи}

% \section{Описание практической части}
% \textit{датасетов}\footnote{
% 				\textbf{Датасет} (англ. \textit{dataset}) -- то же, что и набор данных.
% 				} 
% \section{Заключение}

\newpage

\begin{thebibliography}{00}

	\bibitem{style_transfer}
	\textbf{J.Johnson, A.Alahi, L.Fei-Fei}.
	\emph{Perceptual Losses for Real-Time Style Transfer and Super-Resolution}.
	Department of Computer Science, Stanford University,
	March 2016.

	\bibitem{color_transfer}
	\textbf{R.Zhang, J.-Y.Zhu, P.Isola, X.Geng, A.S.Lin, T.Yu, A.A.Efros}.
	\emph{Real-Time User-Guided Image Colorization with Learned Deep Priors}.
	University of California, Berkeley,
	May 2017.

	\bibitem{CycleGAN}
	\textbf{J.-Y.Zhu, T.Park, P.Isola, A.A.Efros}.
	\emph{Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks}.
	Berkeley AI Research (BAIR) laboratory, UC Berkeley,
	November 2018.

	\bibitem{pix2pix}
	\textbf{P.Isola, J.-Y.Zhu, T.Zhou, A.A.Efros}.
	\emph{Image-to-image translation with conditional adversarial networks}.
	Berkeley AI Research (BAIR) laboratory, UC Berkeley,
	November 2018.

	\bibitem{super_resolution}
	\textbf{Y.Yuan, S.Liu, J.Zhang, Y.Zhang, C.Dong, L.Lin}
	\emph{Unsupervised Image Super-Resolution using Cycle-in-Cycle Generative Adversarial Networks}
	Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University,
	Graduate School at Shenzhen, Department of Automation, Tsinghua University,
	September 2018.

	\bibitem{UNIT}
	\textbf{M.-Y.Liu, T.Breuel, J.Kautz}.
	\emph{Unsupervised Image-to-Image Translation Networks}.
	NVIDIA Corporation,
	Jule 2018.
	
	\bibitem{MUNIT}
	\textbf{X.Huang, M.-Y.Liu, S.Belongie, J.Kautz}.
	\emph{Multimodal Unsupervised Image-to-Image Translation}.
	Cornell University, NVIDIA Corporation,
	August 2018.

	\bibitem{BicycleGAN}
	\textbf{J.-Y.Zhu, R.Zhang, D.Pathak, A.A.Efros}.
	\emph{Toward Multimodal Image-to-Image Translation}.
	Berkeley AI Research, UC Berkeley, Adobe Research,
	October 2018.

	\bibitem{EG-UNIT}
	\textbf{L.Ma, X.Jia, S.Georgoulis, T.Tuytelaars, L.V.Gool}.
	\emph{Exemplar Guided Unsupervised Image-to-Image Translation}.
	Berkeley AI Research, UC Berkeley, Adobe Research,
	March 2019.
	
	\bibitem{Deep_Learning}
	\textbf{С.Николенко, А.Кадурин, Е.Архангельская}.
	\emph{Глубокое обучение}.
	СПб.: Питер, 
	2018.

	\bibitem{ml_lang}
	\textbf{The State of the Octoverse: machine learning} --
	\href{https://github.blog/2019-01-24-the-state-of-the-octoverse-machine-learning/}{GitHub: Report},
	January 2019.

\end{thebibliography}

\end{document}